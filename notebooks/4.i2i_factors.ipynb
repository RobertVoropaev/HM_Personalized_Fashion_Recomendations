{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import implicit\n",
    "import catboost\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.utils import *\n",
    "from src.dataset import *\n",
    "from src.trending import *\n",
    "\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier, cv\n",
    "from catboost.utils import get_roc_curve, create_cd\n",
    "from catboost.eval.catboost_evaluation import CatboostEvaluation\n",
    "\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "tqdm.pandas()\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "N = 12\n",
    "TEST_ON = 1\n",
    "\n",
    "cv_iteration = 0\n",
    "\n",
    "dataset = Dataset(skip_days=7 * cv_iteration, test_days=7 * TEST_ON)\n",
    "train, test = dataset.get_train_and_test()\n",
    "articles = dataset.get_articles()\n",
    "customers = dataset.get_customers()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d1081b060041d0a3b241ec41640420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105542/105542 [00:40<00:00, 2586.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get similar articles\n"
     ]
    }
   ],
   "source": [
    "min_w1_count_for_actual_article=10\n",
    "similar_count_for_article = 5\n",
    "\n",
    "purch_data = pd.read_csv(\"../tmp/purchase_data_train.csv\", index_col=False, dtype=np.uint32)\n",
    "\n",
    "similar_article_dict = get_similar_items(\n",
    "    train=train, \n",
    "    articles=articles, \n",
    "    customers=customers,\n",
    "    min_w1_count_for_actual_article = min_w1_count_for_actual_article, \n",
    "    similar_num_for_article = similar_count_for_article\n",
    ")\n",
    "\n",
    "art_parent_list = []\n",
    "art_child_list = []\n",
    "art_child_score = []\n",
    "for art_parent in similar_article_dict:\n",
    "    for art_info in similar_article_dict[art_parent]:\n",
    "        if art_info[1] != 0:\n",
    "            art_parent_list.append(art_parent)\n",
    "            art_child_list.append(art_info[0])\n",
    "            art_child_score.append(int(art_info[1]))\n",
    "        \n",
    "similar_data = pd.DataFrame({\"article_id_parent\": art_parent_list, \n",
    "                             \"article_id_child\": art_child_list, \n",
    "                             \"als_similarity\": art_child_score}, dtype=np.uint32)\n",
    "\n",
    "similar_purch_data = (\n",
    "    purch_data.merge(similar_data.rename({\"article_id_parent\": \"article_id\"}, axis=1), \n",
    "                     on=\"article_id\", how=\"inner\")\n",
    "        .drop([\"article_id\"], axis=1)\n",
    "        .rename({\"article_id_child\": \"article_id\", \n",
    "                 \"purchase_score\": \"similar_parent_purchase_score\"}, axis=1)\n",
    ")\n",
    "del similar_article_dict, art_parent_list, art_child_list, art_child_score, similar_data\n",
    "gc.collect()\n",
    "\n",
    "print(\"Get similar articles\")\n",
    "\n",
    "similar_purch_data.to_csv(\"../tmp/als_similarity_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>similar_parent_purchase_score</th>\n",
       "      <th>article_id</th>\n",
       "      <th>als_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3031</td>\n",
       "      <td>6</td>\n",
       "      <td>1300</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3031</td>\n",
       "      <td>6</td>\n",
       "      <td>2912</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3031</td>\n",
       "      <td>6</td>\n",
       "      <td>2060</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3031</td>\n",
       "      <td>6</td>\n",
       "      <td>1309</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3031</td>\n",
       "      <td>6</td>\n",
       "      <td>61076</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135505680</th>\n",
       "      <td>1369176</td>\n",
       "      <td>78899</td>\n",
       "      <td>103269</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135505681</th>\n",
       "      <td>1369176</td>\n",
       "      <td>78899</td>\n",
       "      <td>78528</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135505682</th>\n",
       "      <td>1369176</td>\n",
       "      <td>78899</td>\n",
       "      <td>100477</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135505683</th>\n",
       "      <td>1369176</td>\n",
       "      <td>78899</td>\n",
       "      <td>99771</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135505684</th>\n",
       "      <td>1369176</td>\n",
       "      <td>78899</td>\n",
       "      <td>100347</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50994185 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_id  similar_parent_purchase_score  article_id  \\\n",
       "10                3031                              6        1300   \n",
       "11                3031                              6        2912   \n",
       "12                3031                              6        2060   \n",
       "13                3031                              6        1309   \n",
       "14                3031                              6       61076   \n",
       "...                ...                            ...         ...   \n",
       "135505680      1369176                          78899      103269   \n",
       "135505681      1369176                          78899       78528   \n",
       "135505682      1369176                          78899      100477   \n",
       "135505683      1369176                          78899       99771   \n",
       "135505684      1369176                          78899      100347   \n",
       "\n",
       "           als_similarity  \n",
       "10                     16  \n",
       "11                     16  \n",
       "12                     14  \n",
       "13                     13  \n",
       "14                      8  \n",
       "...                   ...  \n",
       "135505680              14  \n",
       "135505681              11  \n",
       "135505682               7  \n",
       "135505683               5  \n",
       "135505684               4  \n",
       "\n",
       "[50994185 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_purch_data[similar_purch_data.similar_parent_purchase_score != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User, item factors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dbae1d42fa433089642bb6a1978977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factors = 20\n",
    "iterations = 400\n",
    "regularization = 0.01\n",
    "random_state = 1\n",
    "\n",
    "dm = ImplicitDatasetMaker(articles, customers)\n",
    "train_csr = dm.get_coo_matrix(train).tocsr()\n",
    "\n",
    "als = implicit.als.AlternatingLeastSquares(\n",
    "    factors=factors, \n",
    "    iterations=iterations, \n",
    "    regularization=regularization,\n",
    "    use_gpu=True,\n",
    "    num_threads=16,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "als.fit(train_csr, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/105542 [00:00<?, ?it/s]<ipython-input-47-243c132c55ee>:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (article_factors - article_factors.min()) /\n",
      "100%|██████████| 105542/105542 [00:01<00:00, 83467.42it/s]\n"
     ]
    }
   ],
   "source": [
    "art_list = []\n",
    "factors_list = []\n",
    "for article_id, article_num in tqdm(dm.articles_id2num.items()):\n",
    "    article_factors = als.item_factors[article_num].to_numpy()\n",
    "    article_factors = (\n",
    "        (article_factors - article_factors.min()) / \n",
    "        (article_factors.max() - article_factors.min())\n",
    "    )\n",
    "    article_factors *= 255\n",
    "    article_factors = article_factors.astype(np.uint8)\n",
    "    art_list.append(article_id)\n",
    "    factors_list.append(article_factors[0])\n",
    "    \n",
    "article_factors = pd.DataFrame({\"article_id\": art_list, \n",
    "                                \"als_article_features\": factors_list})\n",
    "\n",
    "article_factors.to_csv(\"../tmp/article_factors_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1371980 [00:00<?, ?it/s]<ipython-input-51-b3a5468e0cfc>:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (customer_factors - customer_factors.min()) /\n",
      "100%|██████████| 1371980/1371980 [00:51<00:00, 26673.29it/s]\n"
     ]
    }
   ],
   "source": [
    "cust_list = []\n",
    "factors_list = []\n",
    "for customer_id, customer_num in tqdm(dm.customers_id2num.items()):\n",
    "    customer_factors = als.user_factors[customer_num].to_numpy()\n",
    "    customer_factors = (\n",
    "        (customer_factors - customer_factors.min()) / \n",
    "        (customer_factors.max() - customer_factors.min())\n",
    "    )\n",
    "    customer_factors *= 255\n",
    "    customer_factors = customer_factors.astype(np.uint8)\n",
    "    cust_list.append(customer_id)\n",
    "    factors_list.append(customer_factors[0])\n",
    "    \n",
    "customer_factors = pd.DataFrame({\"customer_id\": cust_list, \n",
    "                                \"als_customer_features\": factors_list})\n",
    "\n",
    "customer_factors.to_csv(\"../tmp/customer_factors_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "N = 20\n",
    "TEST_ON = 0\n",
    "\n",
    "cv_iteration = 0\n",
    "\n",
    "dataset = Dataset(skip_days=7 * cv_iteration, test_days=7 * TEST_ON)\n",
    "train, test = dataset.get_train_and_test()\n",
    "articles = dataset.get_articles()\n",
    "customers = dataset.get_customers()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_w1_count_for_actual_article=10\n",
    "similar_count_for_article = 3\n",
    "\n",
    "purch_data = pd.read_csv(\"../tmp/purchase_data_test.csv\", index_col=False, dtype=np.uint32)\n",
    "\n",
    "similar_article_dict = get_similar_items(\n",
    "    train=train, \n",
    "    articles=articles, \n",
    "    customers=customers,\n",
    "    min_w1_count_for_actual_article = min_w1_count_for_actual_article, \n",
    "    similar_num_for_article = similar_count_for_article\n",
    ")\n",
    "\n",
    "art_parent_list = []\n",
    "art_child_list = []\n",
    "art_child_score = []\n",
    "for art_parent in similar_article_dict:\n",
    "    for art_info in similar_article_dict[art_parent]:\n",
    "        if art_info[1] != 0:\n",
    "            art_parent_list.append(art_parent)\n",
    "            art_child_list.append(art_info[0])\n",
    "            art_child_score.append(int(art_info[1]))\n",
    "        \n",
    "similar_data = pd.DataFrame({\"article_id_parent\": art_parent_list, \n",
    "                             \"article_id_child\": art_child_list, \n",
    "                             \"als_similarity\": art_child_score}, dtype=np.uint32)\n",
    "\n",
    "similar_purch_data = (\n",
    "    purch_data.merge(similar_data.rename({\"article_id_parent\": \"article_id\"}, axis=1), \n",
    "                     on=\"article_id\", how=\"inner\")\n",
    "        .drop([\"article_id\"], axis=1)\n",
    "        .rename({\"article_id_child\": \"article_id\", \n",
    "                 \"purchase_score\": \"similar_parent_purchase_score\"}, axis=1)\n",
    ")\n",
    "del similar_article_dict, art_parent_list, art_child_list, art_child_score, similar_data\n",
    "gc.collect()\n",
    "\n",
    "print(\"Get similar articles\")\n",
    "\n",
    "similar_purch_data.to_csv(\"../tmp/als_similarity_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff43b88eec674d18814c952aaad3e122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factors = 20\n",
    "iterations = 400\n",
    "regularization = 0.01\n",
    "random_state = 1\n",
    "\n",
    "dm = ImplicitDatasetMaker(articles, customers)\n",
    "train_csr = dm.get_coo_matrix(train).tocsr()\n",
    "\n",
    "als = implicit.als.AlternatingLeastSquares(\n",
    "    factors=factors, \n",
    "    iterations=iterations, \n",
    "    regularization=regularization,\n",
    "    use_gpu=True,\n",
    "    num_threads=16,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "als.fit(train_csr, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/105542 [00:00<?, ?it/s]<ipython-input-58-3429ba35500a>:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (article_factors - article_factors.min()) /\n",
      "100%|██████████| 105542/105542 [00:04<00:00, 26013.25it/s]\n"
     ]
    }
   ],
   "source": [
    "art_list = []\n",
    "factors_list = []\n",
    "for article_id, article_num in tqdm(dm.articles_id2num.items()):\n",
    "    article_factors = als.item_factors[article_num].to_numpy()\n",
    "    article_factors = (\n",
    "        (article_factors - article_factors.min()) / \n",
    "        (article_factors.max() - article_factors.min())\n",
    "    )\n",
    "    article_factors *= 255\n",
    "    article_factors = article_factors.astype(np.uint8)\n",
    "    art_list.append(article_id)\n",
    "    factors_list.append(article_factors[0])\n",
    "    \n",
    "article_factors = pd.DataFrame({\"article_id\": art_list, \n",
    "                                \"als_article_features\": factors_list})\n",
    "article_factors.to_csv(\"../tmp/article_factors_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1371980 [00:00<?, ?it/s]<ipython-input-59-8c5f6ce17149>:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (customer_factors - customer_factors.min()) /\n",
      "100%|██████████| 1371980/1371980 [00:15<00:00, 86597.04it/s]\n"
     ]
    }
   ],
   "source": [
    "cust_list = []\n",
    "factors_list = []\n",
    "for customer_id, customer_num in tqdm(dm.customers_id2num.items()):\n",
    "    customer_factors = als.user_factors[customer_num].to_numpy()\n",
    "    customer_factors = (\n",
    "        (customer_factors - customer_factors.min()) / \n",
    "        (customer_factors.max() - customer_factors.min())\n",
    "    )\n",
    "    customer_factors *= 255\n",
    "    customer_factors = customer_factors.astype(np.uint8)\n",
    "    cust_list.append(customer_id)\n",
    "    factors_list.append(customer_factors[0])\n",
    "    \n",
    "customer_factors = pd.DataFrame({\"customer_id\": cust_list, \n",
    "                                \"als_customer_features\": factors_list})\n",
    "customer_factors.to_csv(\"../tmp/customer_factors_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
