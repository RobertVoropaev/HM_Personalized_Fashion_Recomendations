{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import implicit\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.utils import *\n",
    "from src.dataset import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "tqdm.pandas()\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitDatasetMaker:\n",
    "    def __init__(self, \n",
    "                 articles, \n",
    "                 customers):        \n",
    "        self.articles_num2id = dict(enumerate(articles[\"article_id\"].unique()))\n",
    "        self.articles_id2num = {id_: num for num, id_  in self.articles_num2id.items()}\n",
    "\n",
    "        self.customers_num2id = dict(enumerate(customers[\"customer_id\"].unique()))\n",
    "        self.customers_id2num = {id_: num for num, id_ in self.customers_num2id.items()}\n",
    "\n",
    "        self.data_shape = (customers.shape[0], articles.shape[0])\n",
    "\n",
    "    def get_coo_matrix(self, data):\n",
    "        data_csr = coo_matrix(\n",
    "            (\n",
    "                np.ones(data.shape[0]), \n",
    "                (\n",
    "                    data[\"customer_id\"].map(self.customers_id2num), \n",
    "                    data[\"article_id\"].map(self.articles_id2num)\n",
    "                )\n",
    "            ),\n",
    "            shape=self.data_shape,\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        return data_csr\n",
    "\n",
    "    def split_data(self, data, val_days: int = 7):\n",
    "        val_split_date = data['t_dat'].max() - pd.Timedelta(val_days)\n",
    "\n",
    "        data_train = data[data['t_dat'] < val_split_date]\n",
    "        data_val = data[data['t_dat'] >= val_split_date]\n",
    "        return data_train, data_val\n",
    "\n",
    "    def limit_data(self, data, min_days_ago: int = 30, max_days_ago: int = 0):\n",
    "        min_split_date = data['t_dat'].max() - pd.Timedelta(days=min_days_ago)\n",
    "        max_split_date = data['t_dat'].max() - pd.Timedelta(days=max_days_ago)\n",
    "\n",
    "        return data[data['t_dat'].between(min_split_date, max_split_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_items(train, articles, \n",
    "                      factors = 200, iterations = 5, regularization = 0.01, \n",
    "                      min_w1_count_for_actual_article = 10, similar_count_for_article = 10):\n",
    "\n",
    "    # Fit model\n",
    "    dm = ImplicitDatasetMaker(articles, customers)\n",
    "    train_csr = dm.get_coo_matrix(train).tocsr()\n",
    "\n",
    "    als = implicit.als.AlternatingLeastSquares(\n",
    "        factors=factors, \n",
    "        iterations=iterations, \n",
    "        regularization=regularization,\n",
    "        use_gpu=True,\n",
    "        num_threads=16,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    als.fit(train_csr, show_progress=True)\n",
    "    \n",
    "    # Actual article count\n",
    "    last_date = train[\"t_dat\"].max()\n",
    "\n",
    "    article_counter_w1 = (\n",
    "        train[train[\"t_dat\"] >= last_date - pd.Timedelta(days=7)]\n",
    "            .groupby(\"article_id\").size()\n",
    "    ).to_dict()\n",
    "\n",
    "    article_counter_w1 = dict(\n",
    "        filter(lambda x: x[1] > min_w1_count_for_actual_article, \n",
    "               article_counter_w1.items()\n",
    "              )\n",
    "    )\n",
    "    \n",
    "    # Get similar\n",
    "    actual_article_list = list(\n",
    "        map(lambda x: dm.articles_id2num[x],\n",
    "            list(article_counter_w1.keys())\n",
    "           )\n",
    "    )\n",
    "\n",
    "    similar_article_dict = defaultdict(list)\n",
    "    for article_id, article_num in tqdm(dm.articles_id2num.items()):\n",
    "        items, scores = als.similar_items(\n",
    "            itemid=article_num, \n",
    "            N=similar_count_for_article, \n",
    "            items=actual_article_list\n",
    "        )\n",
    "        for i in range(len(items)):\n",
    "            article_id_simular = dm.articles_num2id[items[i]]\n",
    "            similar_score = scores[i] * article_counter_w1[article_id_simular]\n",
    "            similar_article_dict[article_id].append((article_id_simular, similar_score))\n",
    "\n",
    "    for article_id in similar_article_dict:\n",
    "        similar_article_dict[article_id] = sorted(similar_article_dict[article_id], \n",
    "                                                  key=lambda x: -x[1])\n",
    "    return similar_article_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quotient(train):\n",
    "    df = train[['t_dat', 'customer_id', 'article_id']]\n",
    "    \n",
    "    last_ts = df['t_dat'].max()\n",
    "    df['ldbw'] = df['t_dat'].parallel_apply(lambda d: last_ts - (last_ts - d).floor('7D')) \n",
    "\n",
    "    weekly_sales = (\n",
    "        df.drop('customer_id', axis=1)\n",
    "        .groupby(['ldbw', 'article_id']).count()\n",
    "        .rename(columns={'t_dat': 'count'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    last_day = last_ts.strftime('%Y-%m-%d')\n",
    "    weekly_sales_targ = (\n",
    "        weekly_sales[weekly_sales['ldbw'] == last_day][['article_id', 'count']]\n",
    "            .rename({\"count\": \"count_targ\"}, axis=1)\n",
    "    )\n",
    "\n",
    "    df = df.merge(weekly_sales, on=['ldbw', 'article_id'])\n",
    "    df = df.merge(weekly_sales_targ, on='article_id', how=\"left\")\n",
    "\n",
    "    df['count_targ'].fillna(0, inplace=True)\n",
    "    df['quotient'] = df['count_targ'] / df['count']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_purchase_dict(df):\n",
    "    last_ts = df['t_dat'].max()\n",
    "    def get_tr_score(line):\n",
    "        x = max(1, (last_ts - line['t_dat']).days)\n",
    "        a, b, c, d = 2.5e4, 1.5e5, 2e-1, 1e3\n",
    "        y = a / np.sqrt(x) + b * np.exp(-c*x) - d # коэфф. временного затухания\n",
    "        return line['quotient'] * max(0, y)\n",
    "\n",
    "    df[\"tr_score\"] = df[['t_dat', \"quotient\"]].parallel_apply(get_tr_score, axis=1)\n",
    "\n",
    "    cust_art_score = (\n",
    "        df.groupby([\"customer_id\", \"article_id\"])[\"tr_score\"].sum()\n",
    "            .reset_index().values\n",
    "    )\n",
    "\n",
    "    purchase_dict = {}\n",
    "    for line in tqdm(cust_art_score):\n",
    "        cust_id, art_id, score = line\n",
    "\n",
    "        if cust_id not in purchase_dict:\n",
    "            purchase_dict[cust_id] = {}\n",
    "\n",
    "        purchase_dict[cust_id][art_id] = score\n",
    "        \n",
    "    return purchase_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_popular_dict(df, customers):\n",
    "    group_art_sum = (\n",
    "        df.merge(customers[[\"customer_id\", \"age_group\"]], on=\"customer_id\", how=\"inner\")\n",
    "            .groupby(['article_id', \"age_group\"])['quotient'].sum()\n",
    "    )\n",
    "\n",
    "    group_popular_dict = {}\n",
    "    for age_group in tqdm(group_art_sum.index.levels[1].tolist()):\n",
    "        group_popular = (\n",
    "            group_art_sum[(group_art_sum.index.get_level_values(\"age_group\") == age_group)]\n",
    "                .nlargest(N)\n",
    "                .index.get_level_values(\"article_id\")\n",
    "        ).tolist()\n",
    "        group_popular_dict[age_group] = group_popular\n",
    "    return group_popular_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(customers, \n",
    "                   purchase_dict, \n",
    "                   pairs, \n",
    "                   similar_article_dict, \n",
    "                   group_popular_dict, \n",
    "                   purchase_value_limit = 5000):\n",
    "    def predict(line):\n",
    "        cust_id = line[\"customer_id\"]\n",
    "        age_group = line[\"age_group\"]\n",
    "\n",
    "        prediction = []\n",
    "        if cust_id in purchase_dict:\n",
    "            series = pd.Series(purchase_dict[cust_id])\n",
    "            series = series[series > purchase_value_limit]\n",
    "            l = series.nlargest(N).index.tolist()\n",
    "            prediction.extend(l)\n",
    "\n",
    "            for elm in l:\n",
    "                if int(elm) in pairs.keys():\n",
    "                    itm = pairs[int(elm)]\n",
    "                    if ('0' + str(itm)) not in prediction:\n",
    "                        prediction.append('0' + str(itm))\n",
    "\n",
    "            series = pd.Series(purchase_dict[cust_id])\n",
    "            series = series[series <= purchase_value_limit]\n",
    "            l = series.nlargest(N).index.tolist()\n",
    "            for elm in l:\n",
    "                itm = similar_article_dict[elm][0][0]\n",
    "                if itm not in prediction:\n",
    "                    prediction.append(itm)\n",
    "\n",
    "        for elm in group_popular_dict[age_group]:\n",
    "            if elm not in prediction:\n",
    "                prediction.append(elm)\n",
    "\n",
    "        return ' '.join(prediction[:N])\n",
    "    \n",
    "    customers['prediction'] = customers[[\"customer_id\", \"age_group\"]].parallel_apply(predict, axis=1)\n",
    "    return customers[[\"customer_id\", \"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_at_k(line, k: int = 12):\n",
    "    actual = line[\"true\"]\n",
    "    predicted = line[\"prediction\"]\n",
    "    \n",
    "    actual = actual.split(\" \")\n",
    "    predicted = predicted.split(\" \")\n",
    "    \n",
    "    if actual == []:\n",
    "        return Exception(\"Empty actual\")\n",
    "    predicted = predicted[:k]\n",
    "    \n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if (p in actual) and (p not in predicted[:i]):\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    score /= min(len(actual), k)\n",
    "            \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_articles(transactions) -> pd.Series:\n",
    "    return (\n",
    "        transactions.groupby(\"customer_id\")[\"article_id\"].apply(\" \".join)\n",
    "            .reset_index().rename({\"article_id\": \"true\"}, axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d5685f99fa4b718117169a7aa3a97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105542/105542 [01:19<00:00, 1326.35it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc81585b0a1b49acaeb934522eae13f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3943502), Label(value='0 / 3943502…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c480e1a0dff6>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ldbw'] = df['t_dat'].parallel_apply(lambda d: last_ts - (last_ts - d).floor('7D'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30abdf3802a7454a80018183321dd5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3943502), Label(value='0 / 3943502…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27101148/27101148 [00:15<00:00, 1802504.74it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.90it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35538d93b176493798e8e688f7f960dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=171498), Label(value='0 / 171498')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 1\n",
    "N = 12\n",
    "TEST_ON = 1\n",
    "\n",
    "min_w1_count_for_actual_article = 10\n",
    "similar_count_for_article = 10\n",
    "purchase_value_limit = 5000\n",
    "\n",
    "cv_iteration = 0\n",
    "dataset = Dataset(skip_days=7 * cv_iteration, test_days=7 * TEST_ON)\n",
    "train, test = dataset.get_train_and_test()\n",
    "articles = dataset.get_articles()\n",
    "customers = dataset.get_customers()\n",
    "\n",
    "similar_article_dict = get_similar_items(\n",
    "    train=train, \n",
    "    articles=articles, \n",
    "    min_w1_count_for_actual_article = min_w1_count_for_actual_article, \n",
    "    similar_count_for_article = similar_count_for_article\n",
    "\n",
    ")\n",
    "\n",
    "train = add_quotient(train=train)\n",
    "purchase_dict = get_purchase_dict(df=train)\n",
    "group_popular_dict = get_group_popular_dict(df=train, customers=customers)\n",
    "pairs = np.load('../input/pairs_cudf.npy', allow_pickle=True).item()\n",
    "\n",
    "sub = get_prediction(customers=customers, \n",
    "                     purchase_dict=purchase_dict, \n",
    "                     pairs=pairs, \n",
    "                     similar_article_dict=similar_article_dict, \n",
    "                     group_popular_dict=group_popular_dict, \n",
    "                     purchase_value_limit=purchase_value_limit)\n",
    "\n",
    "true = get_true_articles(test).reset_index()\n",
    "sub = sub.merge(true, on=\"customer_id\", how=\"inner\")\n",
    "sub[\"ap\"] = sub.apply(avg_precision_at_k, axis=1)\n",
    "map_score = sub[\"ap\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d691fd216d4f95ac24de355fdf39f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105542/105542 [00:49<00:00, 2116.77it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dcf2aa021544b59045a0717f15fc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3973541), Label(value='0 / 3973541…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c480e1a0dff6>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ldbw'] = df['t_dat'].parallel_apply(lambda d: last_ts - (last_ts - d).floor('7D'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f3ad671e124501875703f80d557148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3973541), Label(value='0 / 3973541…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27306439/27306439 [00:20<00:00, 1350144.72it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa7910de55041da8b66b0fca847fd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=171498), Label(value='0 / 171498')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 1\n",
    "N = 12\n",
    "TEST_ON = 0\n",
    "\n",
    "min_w1_count_for_actual_article = 10\n",
    "similar_count_for_article = 10\n",
    "purchase_value_limit = 2000\n",
    "\n",
    "cv_iteration = 0\n",
    "\n",
    "print(\"Predict start\")\n",
    "dataset = Dataset(skip_days=7 * cv_iteration, test_days=7 * TEST_ON)\n",
    "train, test = dataset.get_train_and_test()\n",
    "articles = dataset.get_articles()\n",
    "customers = dataset.get_customers()\n",
    "print(\"Dataset created\")\n",
    "\n",
    "similar_article_dict = get_similar_items(\n",
    "    train=train, \n",
    "    articles=articles, \n",
    "    min_w1_count_for_actual_article = min_w1_count_for_actual_article, \n",
    "    similar_count_for_article = similar_count_for_article\n",
    ")\n",
    "print(\"Get similar articles\")\n",
    "\n",
    "train = add_quotient(train=train)\n",
    "purchase_dict = get_purchase_dict(df=train)\n",
    "print(\"Get purchase dict\")\n",
    "\n",
    "group_popular_dict = get_group_popular_dict(df=train, customers=customers)\n",
    "print(\"Get popular dict\")\n",
    "\n",
    "pairs = np.load('../input/pairs_cudf.npy', allow_pickle=True).item()\n",
    "print(\"Get pairs\")\n",
    "\n",
    "sub = get_prediction(customers=customers, \n",
    "                     purchase_dict=purchase_dict, \n",
    "                     pairs=pairs, \n",
    "                     similar_article_dict=similar_article_dict, \n",
    "                     group_popular_dict=group_popular_dict, \n",
    "                     purchase_value_limit=purchase_value_limit)\n",
    "print(\"Predict done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../output/1.trending_val_limit_2000.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
