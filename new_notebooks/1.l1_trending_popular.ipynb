{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import implicit\n",
    "import catboost\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.utils import *\n",
    "from src.dataset import *\n",
    "from src.trending import *\n",
    "\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier, cv\n",
    "from catboost.utils import get_roc_curve, create_cd\n",
    "from catboost.eval.catboost_evaluation import CatboostEvaluation\n",
    "\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "tqdm.pandas()\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сборка датасета  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "N = 20\n",
    "TEST_ON = 1\n",
    "\n",
    "cv_iteration = 0\n",
    "\n",
    "dataset = Dataset(skip_days=7 * cv_iteration, test_days=7 * TEST_ON)\n",
    "train, test = dataset.get_train_and_test()\n",
    "articles = dataset.get_articles()\n",
    "customers = dataset.get_customers()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_articles(train, days=7, min_count=20):\n",
    "    articles_counter = (\n",
    "        train[train[\"t_dat\"] >= train[\"t_dat\"].max() - pd.Timedelta(days=days)]\n",
    "            .groupby(\"article_id\").size()\n",
    "    )\n",
    "    actual_list = articles_counter[articles_counter > min_count].index.to_list()\n",
    "    return actual_list\n",
    "\n",
    "actual_articles = get_actual_articles(train)\n",
    "len(actual_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f33f5d4b8f4438a68da538273ea1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3943502), Label(value='0 / 3943502…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rv/projects/HM_Personalized_Fashion_Recomendations/new_notebooks/../src/trending.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ldbw'] = df['t_dat'].parallel_apply(lambda d: last_ts - (last_ts - d).floor('7D'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21d999a616147c09a65744b1f2cf434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3943502), Label(value='0 / 3943502…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27101148/27101148 [00:18<00:00, 1443221.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get purchase dict\n"
     ]
    }
   ],
   "source": [
    "train = add_quotient(train=train)\n",
    "purchase_dict = get_purchase_dict(df=train)\n",
    "\n",
    "cust_list = []\n",
    "art_list = []\n",
    "purch_score_list = []\n",
    "for cust_id in purchase_dict:\n",
    "    for art_id in purchase_dict[cust_id]:\n",
    "        cust_list.append(cust_id)\n",
    "        art_list.append(art_id)\n",
    "        purch_score_list.append(int(purchase_dict[cust_id][art_id]))\n",
    "        \n",
    "purch_data = pd.DataFrame({\"customer_id\": cust_list, \n",
    "                           \"article_id\": art_list, \n",
    "                           \"purchase_score\": purch_score_list}, \n",
    "                          dtype=np.uint32)\n",
    "\n",
    "del cust_list, art_list, purch_score_list, purchase_dict\n",
    "gc.collect()\n",
    "\n",
    "print(\"Get purchase dict\")\n",
    "\n",
    "purch_data.to_csv(\"../tmp/purchase_data_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "purch_data_act = purch_data[purch_data[\"purchase_score\"] != 0]\n",
    "purch_data_act.to_csv(\"../tmp/purchase_data_actual_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_count_popular(train, customers, N=20, days=7):\n",
    "    general_count_popular = (\n",
    "        train[train[\"t_dat\"] >= train[\"t_dat\"].max() - pd.Timedelta(days=days)]\n",
    "            .groupby(\"article_id\").size().nlargest(N)\n",
    "            .reset_index()\n",
    "            .rename({0: \"general_popular_count\"}, axis=1)\n",
    "    )\n",
    "    general_count_popular[\"general_popular_count_rank\"] = np.arange(N)\n",
    "    general_count_popular[\"key\"] = 1\n",
    "    customers[\"key\"] = 1\n",
    "    general_count_popular = (\n",
    "        customers[[\"customer_id\", \"key\"]].merge(general_count_popular, on=\"key\", how=\"inner\")\n",
    "            .drop([\"key\"], axis=1)\n",
    "    )\n",
    "    \n",
    "    del customers[\"key\"]\n",
    "    return general_count_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_trending_sum_popular(train, customers, N=20):\n",
    "    general_trending_popular = (\n",
    "        train.groupby(\"article_id\")['tr_score'].sum().nlargest(N)\n",
    "            .reset_index()\n",
    "            .rename({\"tr_score\": \"general_popular_trending_sum\"}, axis=1)\n",
    "    )\n",
    "    general_trending_popular[\"general_popular_trending_sum\"] = general_trending_popular[\"general_popular_trending_sum\"].astype(np.uint32)\n",
    "    general_trending_popular[\"general_popular_trending_sum_rank\"] = np.arange(N).astype(np.uint8)\n",
    "    general_trending_popular[\"key\"] = 1\n",
    "    customers[\"key\"] = 1\n",
    "    general_trending_popular = (\n",
    "        customers[[\"customer_id\", \"key\"]].merge(general_trending_popular, on=\"key\", how=\"inner\")\n",
    "            .drop([\"key\"], axis=1)\n",
    "    )\n",
    "    \n",
    "    del customers[\"key\"]\n",
    "    return general_trending_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_trending_mean_popular(train, customers, N=20):\n",
    "    group_art_sum = (\n",
    "        train.merge(customers[[\"customer_id\", \"age_group\"]], on=\"customer_id\", how=\"inner\")\n",
    "            .groupby(['article_id', \"age_group\"])['tr_score'].mean()\n",
    "            .reset_index()\n",
    "            .groupby([\"age_group\"])[[\"article_id\", \"tr_score\"]]\n",
    "            .apply(lambda x: x.nlargest(N, \"tr_score\"))\n",
    "            .reset_index()\n",
    "            .rename({\"tr_score\": \"group_popular_trending_mean\"}, axis=1)\n",
    "            .drop([\"level_1\"], axis=1)\n",
    "    )\n",
    "    \n",
    "    group_art_sum[\"group_popular_trending_mean_rank\"] = (\n",
    "        np.array(list(range(N)) * group_art_sum[\"age_group\"].unique().shape[0]).astype(np.uint8)\n",
    "    )\n",
    "    group_art_sum[\"group_popular_trending_mean\"] = group_art_sum[\"group_popular_trending_mean\"].astype(np.uint32)\n",
    "\n",
    "    group_art_sum = (\n",
    "        customers[[\"customer_id\", \"age_group\"]].merge(group_art_sum, on=\"age_group\", how=\"inner\")\n",
    "            .drop([\"age_group\"], axis=1)\n",
    "    )\n",
    "    \n",
    "    return group_art_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_trending_sum_popular(train, customers, N=20):\n",
    "    group_art_sum = (\n",
    "        train.merge(customers[[\"customer_id\", \"age_group\"]], on=\"customer_id\", how=\"inner\")\n",
    "            .groupby(['article_id', \"age_group\"])['tr_score'].sum()\n",
    "            .reset_index()\n",
    "            .groupby([\"age_group\"])[[\"article_id\", \"tr_score\"]]\n",
    "            .apply(lambda x: x.nlargest(N, \"tr_score\"))\n",
    "            .reset_index()\n",
    "            .rename({\"tr_score\": \"group_popular_trending_sum\"}, axis=1)\n",
    "            .drop([\"level_1\"], axis=1)\n",
    "    )\n",
    "\n",
    "    \n",
    "    group_art_sum[\"group_popular_trending_sum_rank\"] = (\n",
    "        np.array(list(range(N)) * group_art_sum[\"age_group\"].unique().shape[0]).astype(np.uint8)\n",
    "    )\n",
    "    group_art_sum[\"group_popular_trending_sum\"] = group_art_sum[\"group_popular_trending_sum\"].astype(np.uint32)\n",
    "\n",
    "    group_art_sum = (\n",
    "        customers[[\"customer_id\", \"age_group\"]].merge(group_art_sum, on=\"age_group\", how=\"inner\")\n",
    "            .drop([\"age_group\"], axis=1)\n",
    "    )\n",
    "    \n",
    "    return group_art_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_count_popular(train, customers, N=20, days=7):\n",
    "    group_art_sum = (\n",
    "        train[train[\"t_dat\"] >= train[\"t_dat\"].max() - pd.Timedelta(days=days)]\n",
    "            .merge(customers[[\"customer_id\", \"age_group\"]], on=\"customer_id\", how=\"inner\")\n",
    "            .groupby(['article_id', \"age_group\"]).size()\n",
    "            .reset_index()\n",
    "            .rename({0: \"group_popular_count\"}, axis=1)\n",
    "            .groupby([\"age_group\"])[[\"article_id\", \"group_popular_count\"]]\n",
    "            .apply(lambda x: x.nlargest(N, \"group_popular_count\"))\n",
    "            .reset_index()\n",
    "            .drop([\"level_1\"], axis=1)\n",
    "    )\n",
    "\n",
    "    \n",
    "    group_art_sum[\"group_popular_count_rank\"] = (\n",
    "        np.array(list(range(N)) * group_art_sum[\"age_group\"].unique().shape[0]).astype(np.uint8)\n",
    "    )\n",
    "    group_art_sum[\"group_popular_count\"] = group_art_sum[\"group_popular_count\"].astype(np.uint32)\n",
    "\n",
    "    group_art_sum = (\n",
    "        customers[[\"customer_id\", \"age_group\"]].merge(group_art_sum, on=\"age_group\", how=\"inner\")\n",
    "            .drop([\"age_group\"], axis=1)\n",
    "    )\n",
    "    \n",
    "    return group_art_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_count_popular = get_general_count_popular(train, customers)\n",
    "general_trending_sum_popular = get_general_trending_sum_popular(train, customers)\n",
    "group_trending_mean_popular = get_group_trending_mean_popular(train, customers)\n",
    "group_trending_sum_popular = get_group_trending_sum_popular(train, customers)\n",
    "group_count_popular = get_group_count_popular(train, customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get pairs\n"
     ]
    }
   ],
   "source": [
    "def get_pairs_data(dataset)\n",
    "pairs = np.load('../input/pairs_cudf.npy', allow_pickle=True).item()\n",
    "\n",
    "art_parent_list = []\n",
    "art_child_list = []\n",
    "for art_parent in pairs:\n",
    "    art_parent_list.append(dataset.articles_id2num[\"0\" + str(art_parent)])\n",
    "    art_child_list.append(dataset.articles_id2num[\"0\" + str(pairs[art_parent])])\n",
    "        \n",
    "pairs_data = pd.DataFrame({\"article_id_parent\": art_parent_list, \n",
    "                             \"article_id_child\": art_child_list}, dtype=np.uint32)\n",
    "\n",
    "pairs_data = (\n",
    "    purch_data_act\n",
    "        .merge(pairs_data.rename({\"article_id_parent\": \"article_id\"}, axis=1), \n",
    "               on=\"article_id\", how=\"inner\")\n",
    "        .drop([\"article_id\"], axis=1)\n",
    "        .rename({\"article_id_child\": \"article_id\", \n",
    "                 \"purchase_score\": \"pairs_parent_purchase_score\"}, axis=1)\n",
    ")\n",
    "\n",
    "del pairs, art_parent_list, art_child_list\n",
    "gc.collect()\n",
    "\n",
    "print(\"Get pairs\")\n",
    "pairs_data.to_csv(\"../tmp/pairs_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>purchase_score</th>\n",
       "      <th>general_popular_count</th>\n",
       "      <th>general_popular_count_rank</th>\n",
       "      <th>general_popular_trending_sum</th>\n",
       "      <th>general_popular_trending_sum_rank</th>\n",
       "      <th>group_popular_trending_mean</th>\n",
       "      <th>group_popular_trending_mean_rank</th>\n",
       "      <th>group_popular_trending_sum</th>\n",
       "      <th>group_popular_trending_sum_rank</th>\n",
       "      <th>group_popular_count</th>\n",
       "      <th>group_popular_count_rank</th>\n",
       "      <th>pairs_parent_purchase_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16003</td>\n",
       "      <td>330.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16003</td>\n",
       "      <td>330.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16023</td>\n",
       "      <td>28864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65667</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>78719</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92345332</th>\n",
       "      <td>1218691</td>\n",
       "      <td>93412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92345333</th>\n",
       "      <td>1219679</td>\n",
       "      <td>28970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92345334</th>\n",
       "      <td>1238517</td>\n",
       "      <td>95228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92345335</th>\n",
       "      <td>1359561</td>\n",
       "      <td>95228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92345336</th>\n",
       "      <td>1368904</td>\n",
       "      <td>39590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78899.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92345337 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          customer_id  article_id  purchase_score  general_popular_count  \\\n",
       "0                   0       16003           330.0                    NaN   \n",
       "1                   0       16003           330.0                    NaN   \n",
       "2                   0       16023         28864.0                    NaN   \n",
       "3                   0       65667            48.0                    NaN   \n",
       "4                   0       78719             7.0                    NaN   \n",
       "...               ...         ...             ...                    ...   \n",
       "92345332      1218691       93412             NaN                    NaN   \n",
       "92345333      1219679       28970             NaN                    NaN   \n",
       "92345334      1238517       95228             NaN                    NaN   \n",
       "92345335      1359561       95228             NaN                    NaN   \n",
       "92345336      1368904       39590             NaN                    NaN   \n",
       "\n",
       "          general_popular_count_rank  general_popular_trending_sum  \\\n",
       "0                                NaN                           NaN   \n",
       "1                                NaN                           NaN   \n",
       "2                                NaN                           NaN   \n",
       "3                                NaN                           NaN   \n",
       "4                                NaN                           NaN   \n",
       "...                              ...                           ...   \n",
       "92345332                         NaN                           NaN   \n",
       "92345333                         NaN                           NaN   \n",
       "92345334                         NaN                           NaN   \n",
       "92345335                         NaN                           NaN   \n",
       "92345336                         NaN                           NaN   \n",
       "\n",
       "          general_popular_trending_sum_rank  group_popular_trending_mean  \\\n",
       "0                                       NaN                          NaN   \n",
       "1                                       NaN                          NaN   \n",
       "2                                       NaN                          NaN   \n",
       "3                                       NaN                          NaN   \n",
       "4                                       NaN                          NaN   \n",
       "...                                     ...                          ...   \n",
       "92345332                                NaN                          NaN   \n",
       "92345333                                NaN                          NaN   \n",
       "92345334                                NaN                          NaN   \n",
       "92345335                                NaN                          NaN   \n",
       "92345336                                NaN                          NaN   \n",
       "\n",
       "          group_popular_trending_mean_rank  group_popular_trending_sum  \\\n",
       "0                                      NaN                         NaN   \n",
       "1                                      NaN                         NaN   \n",
       "2                                      NaN                         NaN   \n",
       "3                                      NaN                         NaN   \n",
       "4                                      NaN                         NaN   \n",
       "...                                    ...                         ...   \n",
       "92345332                               NaN                         NaN   \n",
       "92345333                               NaN                         NaN   \n",
       "92345334                               NaN                         NaN   \n",
       "92345335                               NaN                         NaN   \n",
       "92345336                               NaN                         NaN   \n",
       "\n",
       "          group_popular_trending_sum_rank  group_popular_count  \\\n",
       "0                                     NaN                  NaN   \n",
       "1                                     NaN                  NaN   \n",
       "2                                     NaN                  NaN   \n",
       "3                                     NaN                  NaN   \n",
       "4                                     NaN                  NaN   \n",
       "...                                   ...                  ...   \n",
       "92345332                              NaN                  NaN   \n",
       "92345333                              NaN                  NaN   \n",
       "92345334                              NaN                  NaN   \n",
       "92345335                              NaN                  NaN   \n",
       "92345336                              NaN                  NaN   \n",
       "\n",
       "          group_popular_count_rank  pairs_parent_purchase_score  \n",
       "0                              NaN                      28864.0  \n",
       "1                              NaN                          6.0  \n",
       "2                              NaN                          NaN  \n",
       "3                              NaN                          NaN  \n",
       "4                              NaN                          NaN  \n",
       "...                            ...                          ...  \n",
       "92345332                       NaN                     108770.0  \n",
       "92345333                       NaN                      95755.0  \n",
       "92345334                       NaN                      54385.0  \n",
       "92345335                       NaN                      12707.0  \n",
       "92345336                       NaN                      78899.0  \n",
       "\n",
       "[92345337 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data = (\n",
    "    purch_data_act\n",
    "        .merge(general_count_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(general_trending_sum_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(group_trending_mean_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(group_trending_sum_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(group_count_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(pairs_data, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    ")\n",
    "merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data.to_csv(\"../tmp/purch_popular_pairs_train.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "N = 20\n",
    "TEST_ON = 0\n",
    "\n",
    "cv_iteration = 0\n",
    "\n",
    "dataset = Dataset(skip_days=7 * cv_iteration, test_days=7 * TEST_ON)\n",
    "train, test = dataset.get_train_and_test()\n",
    "articles = dataset.get_articles()\n",
    "customers = dataset.get_customers()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3d402cb4eb49be983ca4258739b06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3973541), Label(value='0 / 3973541…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rv/projects/HM_Personalized_Fashion_Recomendations/new_notebooks/../src/trending.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ldbw'] = df['t_dat'].parallel_apply(lambda d: last_ts - (last_ts - d).floor('7D'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469d2fe6cada44c7ac512db940ac1d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3973541), Label(value='0 / 3973541…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27306439/27306439 [00:18<00:00, 1503451.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get purchase dict\n"
     ]
    }
   ],
   "source": [
    "train = add_quotient(train=train)\n",
    "purchase_dict = get_purchase_dict(df=train)\n",
    "\n",
    "cust_list = []\n",
    "art_list = []\n",
    "purch_score_list = []\n",
    "for cust_id in purchase_dict:\n",
    "    for art_id in purchase_dict[cust_id]:\n",
    "        cust_list.append(cust_id)\n",
    "        art_list.append(art_id)\n",
    "        purch_score_list.append(int(purchase_dict[cust_id][art_id]))\n",
    "        \n",
    "purch_data = pd.DataFrame({\"customer_id\": cust_list, \n",
    "                           \"article_id\": art_list, \n",
    "                           \"purchase_score\": purch_score_list}, \n",
    "                          dtype=np.uint32)\n",
    "\n",
    "del cust_list, art_list, purch_score_list, purchase_dict\n",
    "gc.collect()\n",
    "\n",
    "print(\"Get purchase dict\")\n",
    "\n",
    "purch_data.to_csv(\"../tmp/purchase_data_test.csv\", index=False)\n",
    "\n",
    "purch_data_act = purch_data[purch_data[\"purchase_score\"] != 0]\n",
    "purch_data_act.to_csv(\"../tmp/purchase_data_actual_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_count_popular = get_general_count_popular(train, customers)\n",
    "general_trending_sum_popular = get_general_trending_sum_popular(train, customers)\n",
    "group_trending_mean_popular = get_group_trending_mean_popular(train, customers)\n",
    "group_trending_sum_popular = get_group_trending_sum_popular(train, customers)\n",
    "group_count_popular = get_group_count_popular(train, customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get pairs\n"
     ]
    }
   ],
   "source": [
    "pairs = np.load('../input/pairs_cudf.npy', allow_pickle=True).item()\n",
    "\n",
    "art_parent_list = []\n",
    "art_child_list = []\n",
    "for art_parent in pairs:\n",
    "    art_parent_list.append(dataset.articles_id2num[\"0\" + str(art_parent)])\n",
    "    art_child_list.append(dataset.articles_id2num[\"0\" + str(pairs[art_parent])])\n",
    "        \n",
    "pairs_data = pd.DataFrame({\"article_id_parent\": art_parent_list, \n",
    "                             \"article_id_child\": art_child_list}, dtype=np.uint32)\n",
    "\n",
    "pairs_data = (\n",
    "    purch_data_act\n",
    "        .merge(pairs_data.rename({\"article_id_parent\": \"article_id\"}, axis=1), \n",
    "               on=\"article_id\", how=\"inner\")\n",
    "        .drop([\"article_id\"], axis=1)\n",
    "        .rename({\"article_id_child\": \"article_id\", \n",
    "                 \"purchase_score\": \"pairs_parent_purchase_score\"}, axis=1)\n",
    ")\n",
    "\n",
    "del pairs, art_parent_list, art_child_list\n",
    "gc.collect()\n",
    "\n",
    "print(\"Get pairs\")\n",
    "pairs_data.to_csv(\"../tmp/pairs_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = (\n",
    "    purch_data_act\n",
    "        .merge(general_count_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(general_trending_sum_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(group_trending_mean_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(group_trending_sum_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(group_count_popular, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    "        .merge(pairs_data, on=[\"customer_id\", \"article_id\"], how='outer')\n",
    ")\n",
    "merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data.to_csv(\"../tmp/purch_popular_pairs_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
